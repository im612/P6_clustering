# -*- coding: utf-8 -*-
"""MEREU_Ilaria_1-4-notebook-images-CNN-juillet-2022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZoHpvtjKGWWh1UOywF3R2NIh0By_DHJ1

# 1.1 . Traitement des images. Approche CNN / Mobilenet

## Import du dataset
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os 
import sys

# import opencv-python

# !{sys.executable} -m pip install opencv-python
# !{sys.executable} -m pip install keras
# !{sys.executable} -m pip install tensorflow

# %matplotlib inline

import pandas as pd

# lavezzi
# nom_source = "/Users/ilaria/Jottacloud/lavoro/priorita-progetti/" \
#              "alta_priorita/openclassrooms/FOAD Data Scientist/P6/" \
#              "testo/data/source/Flipkart/flipkart_com-ecommerce_sample_1050.csv"

# gennargentu
# nom_source = "/Users/macintosh/Jottacloud/lavoro/priorita-progetti/" \
            #  "alta_priorita/openclassrooms/FOAD Data Scientist/P6/" \
            #  "testo/data/source/Flipkart/flipkart_com-ecommerce_sample_1050.csv"

# colab
nom_source = "drive/MyDrive/Colab_Notebooks/P6/immagini/webinar/Flipkart"
full_path = os.path.join(nom_source, 'flipkart_com-ecommerce_sample_1050.csv')
df = pd.read_csv(full_path, sep= ',', low_memory=False )# Préparation du dataset
df.shape

# List photos 1
# lavezzi
# path = "/Users/ilaria/Jottacloud/lavoro/priorita-progetti/" \
#              "alta_priorita/openclassrooms/FOAD Data Scientist/P6/testo/data/source/Flipkart/Images/"

# gennargentu
# path = "/Users/macintosh/Jottacloud/lavoro/priorita-progetti/" \
            #  "alta_priorita/openclassrooms/FOAD Data Scientist/P6/testo/data/source/Flipkart/Images/"

# colab

path = "Flipkart/Images/"

# list_photos = [file for file in listdir(path)]
# print(len(list_photos))

display(df.head(2))
# List photos 2
list_photos = df['image'].to_list()
print(list_photos)

"""## Catégories"""

list_labels = ['Baby Care ', 'Beauty and Personal Care ', 'Computers ', 'Home Decor & Festive Needs ',
               'Home Furnishing ', 'Kitchen & Dining ', 'Watches ']

# df['first_category'] = df['product_category_tree'].str.extract(r'\[\"(\w* \w*)')
df['first_category'] = df['product_category_tree'].str.extract(r'^\[\"(.+?)[\>\>]')


def dirname(df): 
  cat_dict = { 
  'Baby Care ': 'BabyCare',
  'Beauty and Personal Care ': 'BeautyandPersonalCare',
  'Computers ': 'Computers',
  'Home Decor & Festive Needs ' : 'HomeDecor&FestiveNeeds',
  'Home Furnishing ': 'HomeFurnishing',
  'Kitchen & Dining ': 'Kitchen&Dining', 
  'Watches ': 'Watches'
  }

  df = pd.DataFrame(df)

  # display(df['BuildingType_2015'])
  df['dirname'] = df['first_category'].map(cat_dict)

dirname(df)
df['dirname'].head(5)

"""#Organisation des images"""

# On va réorganiser les images selon la structure indiquée par le tutoriel officiel de tensorflow
# https://www.tensorflow.org/tutorials/load_data/images

!pwd
parent_dir = "/contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16"

dir_names = []

for i in list_labels:
    print(i)

    dfi = df.loc[df['first_category']==i]
    display(dfi.shape)
    dirname = i.replace(" ","")
    dir_names.append(dir_names)
    
    # parent_dir = "../vgg16"

    # Path
    # path = os.path.join(parent_dir, dirname)

    # print(path)
    # Create the directory
    # !mkdir path
   
    # print("Directory '%s' created" % dirname)

    # print(i)

!pwd
parent_dir = "/contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16"

for i in list_labels:
    print(i)
  
# os.makedirs(os.path.join(parent_dir, 'ImagesKeras', 'test', 'test'))

for_ls = os.path.join(parent_dir)
print(for_ls)
!ls drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16
!ls

# !ls /contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16/ImagesKeras/
# !rm -r /contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16/ImagesKeras/test
# !rm -r /contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16/ImagesKeras/train 
# !rm -r /contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16/ImagesKeras/valid
# !ls /contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16/ImagesKeras/

import shutil

os.makedirs(os.path.join(parent_dir, 'ImagesKeras2', 'test', 'test'))

images_dir = 'drive/MyDrive/Colab_Notebooks/P6/immagini/webinar/Flipkart'

test_number = 30

for _dir_ in df['dirname'].unique():
    os.makedirs(os.path.join(parent_dir, 'ImagesKeras2', 'train', _dir_))
    os.makedirs(os.path.join(parent_dir, 'ImagesKeras2', 'valid', _dir_))

    files = df[df['dirname'] == _dir_]['image'].values.tolist()

    srcdir = os.path.join(images_dir, 'Images')

    for maindir in ['train', 'valid', 'test']:
      if maindir == 'test':
        dstdir = os.path.join(parent_dir, 'ImagesKeras2', maindir, 'test')
        sfiles = files[0:test_number]
      elif maindir == 'valid':
        dstdir = os.path.join(parent_dir, 'ImagesKeras2', maindir, _dir_)
        sfiles = files[test_number:test_number+test_number]
      else:
        dstdir = os.path.join(parent_dir, 'ImagesKeras2', maindir, _dir_)
        sfiles = files[test_number:150]

      for _file_ in sfiles:
        shutil.copy(os.path.join(srcdir, _file_), dstdir)

# !ls /contents/drive/MyDrive/Colab_Notebooks/P6/immagini/vgg16/ImagesKeras/*/*

"""# 1.2 . Traitement des images. Approche CNN, Mobilenet 


"""

# %%script false --no-raise-error
from keras.applications.mobilenet import MobileNet 
# https://keras.io/api/applications/mobilenet/
# MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
from keras.layers import Dense, GlobalAveragePooling2D, GlobalAveragePooling1D, Input, Embedding 
from keras.models import Model

base_model=MobileNet(input_shape=(224, 224, 3), weights='imagenet', include_top=False)

x=base_model.output

x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x)
x=Dense(256,activation='relu')(x)
preds=Dense(7,activation='softmax')(x)

model=Model(inputs=base_model.input,outputs=preds)

n_trainable_layers = 4

for i,layer in enumerate(model.layers):
    if i >= (len(model.layers) - n_trainable_layers): 
      layer.trainable = True
    else:
      layer.trainable = False

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%script false --no-raise-error
# # from keras.applications.mobilenet import MobileNet 
# # https://keras.io/api/applications/mobilenet/
# # MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
# from keras.applications.vgg16 import VGG16
# 
# # https://keras.io/api/applications/#usage-examples-for-image-classification-models
# 
# from keras.layers import Dense, GlobalAveragePooling2D, GlobalAveragePooling1D, Input, Embedding 
# from keras.models import Model
# 
# base_model=VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)
# 
# x=base_model.output
# 
# x=GlobalAveragePooling2D()(x)
# x=Dense(1024,activation='relu')(x)
# x=Dense(256,activation='relu')(x)
# preds=Dense(7,activation='softmax')(x)
# 
# model=Model(inputs=base_model.input,outputs=preds)
# 
# n_trainable_layers = 4
# 
# for i,layer in enumerate(model.layers):
#     if i >= (len(model.layers) - n_trainable_layers): 
#       layer.trainable = True
#     else:
#       layer.trainable = False
# 
# model.summary()



from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf

generators = {}

generator = ImageDataGenerator(preprocessing_function=preprocess_input)
 
for maindir in ['train', 'valid', 'test']:

  generators[maindir] = generator.flow_from_directory(
      os.path.join(parent_dir, '
      ', maindir),
      target_size=(224,224),
      color_mode='rgb',
      batch_size=32,
      class_mode='categorical' if maindir != 'test' else None,
      shuffle=maindir!='test',
      seed=42
  )

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

STEP_SIZE_TRAIN = generators['train'].n // generators['train'].batch_size
STEP_SIZE_VALID = generators['valid'].n // generators['valid'].batch_size

with tf.device('/device:GPU:0'):
  model.fit_generator(generator=generators['train'],
                      steps_per_epoch=STEP_SIZE_TRAIN,
                      validation_data=generators['valid'],
                      validation_steps=STEP_SIZE_VALID,
                      epochs=20)

generator_eval = model.evaluate_generator(generator=generators['valid'])
print(f'Évaluation de la validation. loss={generator_eval[0]} / accuracy={generator_eval[1]}')
generators['test'].reset()
pred=model.predict_generator(generators['test'],verbose=1)

predicted_class_indices=np.argmax(pred,axis=1)
labels = (generators['train'].class_indices)
labels = {v:k for k,v in labels.items()}
predictions = [labels[k] for k in predicted_class_indices]
filenames=generators['test'].filenames

results=pd.DataFrame({'image':filenames,
                      'CATEGORY_PREDICT':predictions})

image_features = df[['dirname', 'image']]

image_features.head(2)
image_features['image'] = image_features['image'].apply(lambda x: os.path.join(images_dir, x))
image_features.head(2)

image_features_copy = image_features.copy()
image_features_copy['image'] = image_features_copy['image'].apply(lambda x: x.split('/')[-1])
results['image'] = results['image'].apply(lambda x: x.split('/')[-1])
results = results.merge(image_features_copy, on='image')

results.head()

from sklearn.metrics.cluster import adjusted_rand_score
import datetime

results = results[['dirname','CATEGORY_PREDICT']]

ARI = np.round(adjusted_rand_score(results['dirname'], results['CATEGORY_PREDICT']), 4)

print(f'\nARI : {ARI}\n{datetime.datetime.now()}')

# ARIS['CNN Transfert Learning'] = ARI

"""# 1.2 . Traitement des images. Approche CNN, VGG-16



"""

from keras.applications.mobilenet import MobileNet
from keras.layers import Dense, GlobalAveragePooling2D, GlobalAveragePooling1D, Input, Embedding 
from keras.models import Model

base_model=VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)

x=base_model.output

x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x)
x=Dense(256,activation='relu')(x)
preds=Dense(7,activation='softmax')(x)

model=Model(inputs=base_model.input,outputs=preds)

n_trainable_layers = 4

for i,layer in enumerate(model.layers):
    if i >= (len(model.layers) - n_trainable_layers): 
      layer.trainable = True
    else:
      layer.trainable = False

model.summary()

