{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Ce fichier est le premier sur quatre. Nous allons ici traiter les textes avec les approches BoW (Bag of Words). "
   ],
   "metadata": {
    "id": "uqjPo5DIeFhW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: nltk in /usr/local/lib/python3.9/site-packages (3.7)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from nltk) (8.1.3)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from nltk) (1.1.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/site-packages (from nltk) (2022.8.17)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from nltk) (4.64.0)\r\n",
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: sklearn in /usr/local/lib/python3.9/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from sklearn) (1.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.19.5)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\r\n",
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "#Initialisation\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "import nltk\n",
    "\n",
    "!{sys.executable} -m pip install sklearn\n",
    "\n",
    "# !{sys.executable} -m pip install gensim\n",
    "# !{sys.executable} -m pip install pyLDAvis\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4fPs282mZauY",
    "outputId": "bd670e70-dac6-4fb5-ea35-549330540eb6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "nom_source = \"data/source/Flipkart/flipkart_com-ecommerce_sample_1050.csv\"\n",
    "df = pd.read_csv(nom_source, sep= ',', low_memory=False )"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jdXz71UeqTZg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(1050, 15)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050 entries, 0 to 1049\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   uniq_id                  1050 non-null   object \n",
      " 1   crawl_timestamp          1050 non-null   object \n",
      " 2   product_url              1050 non-null   object \n",
      " 3   product_name             1050 non-null   object \n",
      " 4   product_category_tree    1050 non-null   object \n",
      " 5   pid                      1050 non-null   object \n",
      " 6   retail_price             1049 non-null   float64\n",
      " 7   discounted_price         1049 non-null   float64\n",
      " 8   image                    1050 non-null   object \n",
      " 9   is_FK_Advantage_product  1050 non-null   bool   \n",
      " 10  description              1050 non-null   object \n",
      " 11  product_rating           1050 non-null   object \n",
      " 12  overall_rating           1050 non-null   object \n",
      " 13  brand                    712 non-null    object \n",
      " 14  product_specifications   1049 non-null   object \n",
      "dtypes: bool(1), float64(2), object(12)\n",
      "memory usage: 116.0+ KB\n"
     ]
    }
   ],
   "source": [
    "display(df.shape)\n",
    "df.info()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "y_cb_K51qTZs",
    "outputId": "b7e9717e-6421-46f2-c447-4d13423a4fdb"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14KOdvQYcF8A",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1.1.1 Traitement des textes\n",
    "\n",
    "\n",
    "1.   Tokenisation\n",
    "2.   Stopwords\n",
    "3. Lemmatisation\n",
    "4. Création fonction de combinaison de la description avec le nom du produit\n",
    "5. Choix du texte pour le corpus (description, nom du produit, ou combinaison des deux) pour la création des bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                            uniq_id            crawl_timestamp  \\\n0  55b85ea15a1536d46b7190ad6fff8ce7  2016-04-30 03:22:56 +0000   \n1  7b72c92c2f6c40268628ec5f14c6d590  2016-04-30 03:22:56 +0000   \n2  64d5d4a258243731dc7bbb1eef49ad74  2016-04-30 03:22:56 +0000   \n3  d4684dcdc759dd9cdf41504698d737d8  2016-06-20 08:49:52 +0000   \n4  6325b6870c54cd47be6ebfbffa620ec7  2016-06-20 08:49:52 +0000   \n\n                                         product_url  \\\n0  http://www.flipkart.com/elegance-polyester-mul...   \n1  http://www.flipkart.com/sathiyas-cotton-bath-t...   \n2  http://www.flipkart.com/eurospa-cotton-terry-f...   \n3  http://www.flipkart.com/santosh-royal-fashion-...   \n4  http://www.flipkart.com/jaipur-print-cotton-fl...   \n\n                                        product_name  \\\n0  Elegance Polyester Multicolor Abstract Eyelet ...   \n1                         Sathiyas Cotton Bath Towel   \n2                Eurospa Cotton Terry Face Towel Set   \n3  SANTOSH ROYAL FASHION Cotton Printed King size...   \n4  Jaipur Print Cotton Floral King sized Double B...   \n\n                               product_category_tree               pid  \\\n0  [\"Home Furnishing >> Curtains & Accessories >>...  CRNEG7BKMFFYHQ8Z   \n1  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEGFZHGBXPHZUH   \n2  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEG6SHXTDB2A2Y   \n3  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJT9UQWHDUBH4   \n4  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJTHNGWVGWWQU   \n\n   retail_price  discounted_price                                 image  \\\n0        1899.0             899.0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n1         600.0             449.0  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n2           NaN               NaN  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n3        2699.0            1299.0  d4684dcdc759dd9cdf41504698d737d8.jpg   \n4        2599.0             698.0  6325b6870c54cd47be6ebfbffa620ec7.jpg   \n\n   is_FK_Advantage_product                                        description  \\\n0                    False  Key Features of Elegance Polyester Multicolor ...   \n1                    False  Specifications of Sathiyas Cotton Bath Towel (...   \n2                    False  Key Features of Eurospa Cotton Terry Face Towe...   \n3                    False  Key Features of SANTOSH ROYAL FASHION Cotton P...   \n4                    False  Key Features of Jaipur Print Cotton Floral Kin...   \n\n        product_rating       overall_rating                  brand  \\\n0  No rating available  No rating available               Elegance   \n1  No rating available  No rating available               Sathiyas   \n2  No rating available  No rating available                Eurospa   \n3  No rating available  No rating available  SANTOSH ROYAL FASHION   \n4  No rating available  No rating available           Jaipur Print   \n\n                              product_specifications  \\\n0  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...   \n1  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...   \n2  {\"product_specification\"=>[{\"key\"=>\"Material\",...   \n3  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...   \n4  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...   \n\n                                           descr_new  \\\n0   eyelet door curtain curtain eyelet door curta...   \n1   sathiyas bath towel bath towel bath towel sat...   \n2   face towel face towel face towel face towel f...   \n3   santosh royal fashion king bedsheet royal bed...   \n4   king bedsheet king bedsheet bedsheet bedsheet...   \n\n                                        sentence_bow  \\\n0  eyelet door curtain curtain eyelet door curtai...   \n1  sathiyas bath towel bath towel bath towel sath...   \n2  face towel face towel face towel face towel fa...   \n3  santosh royal fashion king bedsheet royal beds...   \n4  king bedsheet king bedsheet bedsheet bedsheet ...   \n\n                                    sentence_bow_lem  \\\n0  eyelet door curtain curtain eyelet door curtai...   \n1  sathiyas bath towel bath towel bath towel sath...   \n2  face towel face towel face towel face towel fa...   \n3  santosh royal fashion king bedsheet royal beds...   \n4  king bedsheet king bedsheet bedsheet bedsheet ...   \n\n                                         sentence_dl  len_d  \n0  eyelet door curtain curtain eyelet door curtai...    414  \n1  sathiyas bath towel bath towel bath towel sath...    276  \n2  face towel face towel face towel face towel fa...    279  \n3  santosh royal fashion king bedsheet royal beds...    384  \n4  king bedsheet king bedsheet bedsheet bedsheet ...    192  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniq_id</th>\n      <th>crawl_timestamp</th>\n      <th>product_url</th>\n      <th>product_name</th>\n      <th>product_category_tree</th>\n      <th>pid</th>\n      <th>retail_price</th>\n      <th>discounted_price</th>\n      <th>image</th>\n      <th>is_FK_Advantage_product</th>\n      <th>description</th>\n      <th>product_rating</th>\n      <th>overall_rating</th>\n      <th>brand</th>\n      <th>product_specifications</th>\n      <th>descr_new</th>\n      <th>sentence_bow</th>\n      <th>sentence_bow_lem</th>\n      <th>sentence_dl</th>\n      <th>len_d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n      <td>2016-04-30 03:22:56 +0000</td>\n      <td>http://www.flipkart.com/elegance-polyester-mul...</td>\n      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n      <td>[\"Home Furnishing &gt;&gt; Curtains &amp; Accessories &gt;&gt;...</td>\n      <td>CRNEG7BKMFFYHQ8Z</td>\n      <td>1899.0</td>\n      <td>899.0</td>\n      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n      <td>False</td>\n      <td>Key Features of Elegance Polyester Multicolor ...</td>\n      <td>No rating available</td>\n      <td>No rating available</td>\n      <td>Elegance</td>\n      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n      <td>eyelet door curtain curtain eyelet door curta...</td>\n      <td>eyelet door curtain curtain eyelet door curtai...</td>\n      <td>eyelet door curtain curtain eyelet door curtai...</td>\n      <td>eyelet door curtain curtain eyelet door curtai...</td>\n      <td>414</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n      <td>2016-04-30 03:22:56 +0000</td>\n      <td>http://www.flipkart.com/sathiyas-cotton-bath-t...</td>\n      <td>Sathiyas Cotton Bath Towel</td>\n      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n      <td>BTWEGFZHGBXPHZUH</td>\n      <td>600.0</td>\n      <td>449.0</td>\n      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n      <td>False</td>\n      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n      <td>No rating available</td>\n      <td>No rating available</td>\n      <td>Sathiyas</td>\n      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n      <td>sathiyas bath towel bath towel bath towel sat...</td>\n      <td>sathiyas bath towel bath towel bath towel sath...</td>\n      <td>sathiyas bath towel bath towel bath towel sath...</td>\n      <td>sathiyas bath towel bath towel bath towel sath...</td>\n      <td>276</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n      <td>2016-04-30 03:22:56 +0000</td>\n      <td>http://www.flipkart.com/eurospa-cotton-terry-f...</td>\n      <td>Eurospa Cotton Terry Face Towel Set</td>\n      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n      <td>BTWEG6SHXTDB2A2Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n      <td>False</td>\n      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n      <td>No rating available</td>\n      <td>No rating available</td>\n      <td>Eurospa</td>\n      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Material\",...</td>\n      <td>face towel face towel face towel face towel f...</td>\n      <td>face towel face towel face towel face towel fa...</td>\n      <td>face towel face towel face towel face towel fa...</td>\n      <td>face towel face towel face towel face towel fa...</td>\n      <td>279</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d4684dcdc759dd9cdf41504698d737d8</td>\n      <td>2016-06-20 08:49:52 +0000</td>\n      <td>http://www.flipkart.com/santosh-royal-fashion-...</td>\n      <td>SANTOSH ROYAL FASHION Cotton Printed King size...</td>\n      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n      <td>BDSEJT9UQWHDUBH4</td>\n      <td>2699.0</td>\n      <td>1299.0</td>\n      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n      <td>False</td>\n      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n      <td>No rating available</td>\n      <td>No rating available</td>\n      <td>SANTOSH ROYAL FASHION</td>\n      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n      <td>santosh royal fashion king bedsheet royal bed...</td>\n      <td>santosh royal fashion king bedsheet royal beds...</td>\n      <td>santosh royal fashion king bedsheet royal beds...</td>\n      <td>santosh royal fashion king bedsheet royal beds...</td>\n      <td>384</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6325b6870c54cd47be6ebfbffa620ec7</td>\n      <td>2016-06-20 08:49:52 +0000</td>\n      <td>http://www.flipkart.com/jaipur-print-cotton-fl...</td>\n      <td>Jaipur Print Cotton Floral King sized Double B...</td>\n      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n      <td>BDSEJTHNGWVGWWQU</td>\n      <td>2599.0</td>\n      <td>698.0</td>\n      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n      <td>False</td>\n      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n      <td>No rating available</td>\n      <td>No rating available</td>\n      <td>Jaipur Print</td>\n      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet ...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet ...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet ...</td>\n      <td>192</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenizer_fct(sentence) :\n",
    "    # print(sentence)\n",
    "    sentence_clean = sentence.replace('-', ' ').replace('+', ' ').replace('/', ' ').replace('#', ' ')\n",
    "    word_tokens = word_tokenize(sentence_clean)\n",
    "    return word_tokens\n",
    "\n",
    "# Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_w = list(set(stopwords.words('english'))) + ['[', ']', ',', '.', ':', '?', '(', ')', '-']\n",
    "\n",
    "stopwords_specific = ['pack', 'set', 'combo', 'box',\n",
    "                      'jaipur', 'elegance', 'shape',  'print',  'light', 'led',\n",
    "                      'rockmantra', 'eurospa', 'terry',\n",
    "                     'printed','usb', 'print',\n",
    "                     'double', 'single',\n",
    "                     'red', 'brown', 'black', 'multicolor', 'blue', 'color', 'green',\n",
    "                      'abstract', 'floral',\n",
    "                     'vinyl', 'ideal',\n",
    "                     'large', 'comfort', 'extra', 'sized', 'height', 'width', 'lenght',\n",
    "                     'polyester', 'crystal', 'ceramic', 'paper', 'cotton', 'porcelain',\n",
    "                     'lapguard', 'sstudio', 'sonata', 'vgn', 'vaio',\n",
    "                     'gathered', 'printland', 'prithish', 'hot', 'product','maximum']\n",
    "\n",
    "stop_w = stop_w + stopwords_specific\n",
    "\n",
    "def stop_word_filter_fct(list_words) :\n",
    "    filtered_w = [w for w in list_words if not w in stop_w]\n",
    "    filtered_w2 = [w for w in filtered_w if len(w) > 2]\n",
    "    return filtered_w2\n",
    "\n",
    "# lower case et alpha\n",
    "def lower_start_fct(list_words) :\n",
    "    lw = [w.lower() for w in list_words if (not w.startswith(\"@\"))]\n",
    "    #                                   and (not w.startswith(\"#\"))\n",
    "    #                                    and (not w.startswith(\"http\"))]\n",
    "    return lw\n",
    "\n",
    "# Lemmatizer (base d'un mot)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemma_fct(list_words) :\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_w = [lemmatizer.lemmatize(w) for w in list_words]\n",
    "    return lem_w\n",
    "\n",
    "# Fonction de préparation du texte pour le bag of words (Countvectorizer et Tf_idf, Word2Vec)\n",
    "def transform_bow_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(sw)\n",
    "    # lem_w = lemma_fct(lw)\n",
    "    transf_desc_text = ' '.join(lw)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Fonction de préparation du texte pour le bag of words avec lemmatization\n",
    "def transform_bow_lem_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(sw)\n",
    "    lem_w = lemma_fct(lw)\n",
    "    transf_desc_text = ' '.join(lem_w)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Fonction de préparation du texte pour le Deep learning (USE et BERT)\n",
    "def transform_dl_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "#    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(word_tokens)\n",
    "    # lem_w = lemma_fct(lw)\n",
    "    transf_desc_text = ' '.join(lw)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Création d'un texte extrait de la description par l'intersection avec le nom du produit\n",
    "def transform_descr_new() :\n",
    "    s_i = []\n",
    "\n",
    "    for i in range(len((df['description'].values))):\n",
    "    # j = str().split(\" \")\n",
    "    # n = str(df['product_name'].values[i]).replace('-', '').split(\" \")\n",
    "\n",
    "        j = tokenizer_fct(df['description'].values[i])\n",
    "        j = lower_start_fct(j)\n",
    "        n = tokenizer_fct(df['product_name'].values[i])\n",
    "        n = lower_start_fct(n)\n",
    "\n",
    "        for w in n :\n",
    "            # print(w, len(w))\n",
    "            if not w.isalpha() or len(w)<3:\n",
    "                n.remove(w)\n",
    "\n",
    "        if '' in n:\n",
    "            n.remove('')\n",
    "\n",
    "        # print(n)\n",
    "        s = ''\n",
    "        for w in j:\n",
    "            # print(w)\n",
    "            if w in n and w not in stopwords_specific:\n",
    "                # print(w, 'ok')\n",
    "                s = s + ' ' + w\n",
    "\n",
    "        s_i.append(s)\n",
    "\n",
    "    df['descr_new'] = pd.Series(s_i)\n",
    "\n",
    "transform_descr_new()\n",
    "\n",
    "df.head()\n",
    "\n",
    "feats = ['description', 'product_name', 'descr_new']\n",
    "\n",
    "feat_start = feats[2]\n",
    "\n",
    "df['sentence_bow'] = df[feat_start].apply(lambda x : transform_bow_fct(x))\n",
    "df['sentence_bow_lem'] = df[feat_start].apply(lambda x : transform_bow_lem_fct(x))\n",
    "df['sentence_dl'] = df[feat_start].apply(lambda x : transform_dl_fct(x))\n",
    "df['len_d'] = df['sentence_bow'].apply(len)+df['sentence_bow_lem'].apply(len)+(df['sentence_dl']).apply(len)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "2G5uecdtZaux",
    "outputId": "279ed387-fa49-4de0-aa8e-6b982c23b617"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1.2 Élaboration des catégories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "1sgFALeKZau7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                            uniq_id            crawl_timestamp  \\\n0  55b85ea15a1536d46b7190ad6fff8ce7  2016-04-30 03:22:56 +0000   \n1  7b72c92c2f6c40268628ec5f14c6d590  2016-04-30 03:22:56 +0000   \n2  64d5d4a258243731dc7bbb1eef49ad74  2016-04-30 03:22:56 +0000   \n3  d4684dcdc759dd9cdf41504698d737d8  2016-06-20 08:49:52 +0000   \n4  6325b6870c54cd47be6ebfbffa620ec7  2016-06-20 08:49:52 +0000   \n\n                                         product_url  \\\n0  http://www.flipkart.com/elegance-polyester-mul...   \n1  http://www.flipkart.com/sathiyas-cotton-bath-t...   \n2  http://www.flipkart.com/eurospa-cotton-terry-f...   \n3  http://www.flipkart.com/santosh-royal-fashion-...   \n4  http://www.flipkart.com/jaipur-print-cotton-fl...   \n\n                                        product_name  \\\n0  Elegance Polyester Multicolor Abstract Eyelet ...   \n1                         Sathiyas Cotton Bath Towel   \n2                Eurospa Cotton Terry Face Towel Set   \n3  SANTOSH ROYAL FASHION Cotton Printed King size...   \n4  Jaipur Print Cotton Floral King sized Double B...   \n\n                               product_category_tree               pid  \\\n0  [\"Home Furnishing >> Curtains & Accessories >>...  CRNEG7BKMFFYHQ8Z   \n1  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEGFZHGBXPHZUH   \n2  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEG6SHXTDB2A2Y   \n3  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJT9UQWHDUBH4   \n4  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJTHNGWVGWWQU   \n\n   retail_price  discounted_price                                 image  \\\n0        1899.0             899.0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n1         600.0             449.0  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n2           NaN               NaN  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n3        2699.0            1299.0  d4684dcdc759dd9cdf41504698d737d8.jpg   \n4        2599.0             698.0  6325b6870c54cd47be6ebfbffa620ec7.jpg   \n\n   is_FK_Advantage_product  ...  \\\n0                    False  ...   \n1                    False  ...   \n2                    False  ...   \n3                    False  ...   \n4                    False  ...   \n\n                                           descr_new  \\\n0   eyelet door curtain curtain eyelet door curta...   \n1   sathiyas bath towel bath towel bath towel sat...   \n2   face towel face towel face towel face towel f...   \n3   santosh royal fashion king bedsheet royal bed...   \n4   king bedsheet king bedsheet bedsheet bedsheet...   \n\n                                        sentence_bow  \\\n0  eyelet door curtain curtain eyelet door curtai...   \n1  sathiyas bath towel bath towel bath towel sath...   \n2  face towel face towel face towel face towel fa...   \n3  santosh royal fashion king bedsheet royal beds...   \n4  king bedsheet king bedsheet bedsheet bedsheet ...   \n\n                                    sentence_bow_lem  \\\n0  eyelet door curtain curtain eyelet door curtai...   \n1  sathiyas bath towel bath towel bath towel sath...   \n2  face towel face towel face towel face towel fa...   \n3  santosh royal fashion king bedsheet royal beds...   \n4  king bedsheet king bedsheet bedsheet bedsheet ...   \n\n                                         sentence_dl len_d    first_category  \\\n0  eyelet door curtain curtain eyelet door curtai...   414  Home Furnishing    \n1  sathiyas bath towel bath towel bath towel sath...   276        Baby Care    \n2  face towel face towel face towel face towel fa...   279        Baby Care    \n3  santosh royal fashion king bedsheet royal beds...   384  Home Furnishing    \n4  king bedsheet king bedsheet bedsheet bedsheet ...   192  Home Furnishing    \n\n           second_category     third_category  \\\n0  Curtains & Accessories           Curtains    \n1        Baby Bath & Skin   Baby Bath Towels    \n2        Baby Bath & Skin   Baby Bath Towels    \n3               Bed Linen          Bedsheets    \n4               Bed Linen          Bedsheets    \n\n                    fourth_category  fifth_category  \n0                               NaN             NaN  \n1        Sathiyas Baby Bath Towels                >  \n2         Eurospa Baby Bath Towels                >  \n3  SANTOSH ROYAL FASHION Bedsheets                >  \n4           Jaipur Print Bedsheets                >  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniq_id</th>\n      <th>crawl_timestamp</th>\n      <th>product_url</th>\n      <th>product_name</th>\n      <th>product_category_tree</th>\n      <th>pid</th>\n      <th>retail_price</th>\n      <th>discounted_price</th>\n      <th>image</th>\n      <th>is_FK_Advantage_product</th>\n      <th>...</th>\n      <th>descr_new</th>\n      <th>sentence_bow</th>\n      <th>sentence_bow_lem</th>\n      <th>sentence_dl</th>\n      <th>len_d</th>\n      <th>first_category</th>\n      <th>second_category</th>\n      <th>third_category</th>\n      <th>fourth_category</th>\n      <th>fifth_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n      <td>2016-04-30 03:22:56 +0000</td>\n      <td>http://www.flipkart.com/elegance-polyester-mul...</td>\n      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n      <td>[\"Home Furnishing &gt;&gt; Curtains &amp; Accessories &gt;&gt;...</td>\n      <td>CRNEG7BKMFFYHQ8Z</td>\n      <td>1899.0</td>\n      <td>899.0</td>\n      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n      <td>False</td>\n      <td>...</td>\n      <td>eyelet door curtain curtain eyelet door curta...</td>\n      <td>eyelet door curtain curtain eyelet door curtai...</td>\n      <td>eyelet door curtain curtain eyelet door curtai...</td>\n      <td>eyelet door curtain curtain eyelet door curtai...</td>\n      <td>414</td>\n      <td>Home Furnishing</td>\n      <td>Curtains &amp; Accessories</td>\n      <td>Curtains</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n      <td>2016-04-30 03:22:56 +0000</td>\n      <td>http://www.flipkart.com/sathiyas-cotton-bath-t...</td>\n      <td>Sathiyas Cotton Bath Towel</td>\n      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n      <td>BTWEGFZHGBXPHZUH</td>\n      <td>600.0</td>\n      <td>449.0</td>\n      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n      <td>False</td>\n      <td>...</td>\n      <td>sathiyas bath towel bath towel bath towel sat...</td>\n      <td>sathiyas bath towel bath towel bath towel sath...</td>\n      <td>sathiyas bath towel bath towel bath towel sath...</td>\n      <td>sathiyas bath towel bath towel bath towel sath...</td>\n      <td>276</td>\n      <td>Baby Care</td>\n      <td>Baby Bath &amp; Skin</td>\n      <td>Baby Bath Towels</td>\n      <td>Sathiyas Baby Bath Towels</td>\n      <td>&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n      <td>2016-04-30 03:22:56 +0000</td>\n      <td>http://www.flipkart.com/eurospa-cotton-terry-f...</td>\n      <td>Eurospa Cotton Terry Face Towel Set</td>\n      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n      <td>BTWEG6SHXTDB2A2Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n      <td>False</td>\n      <td>...</td>\n      <td>face towel face towel face towel face towel f...</td>\n      <td>face towel face towel face towel face towel fa...</td>\n      <td>face towel face towel face towel face towel fa...</td>\n      <td>face towel face towel face towel face towel fa...</td>\n      <td>279</td>\n      <td>Baby Care</td>\n      <td>Baby Bath &amp; Skin</td>\n      <td>Baby Bath Towels</td>\n      <td>Eurospa Baby Bath Towels</td>\n      <td>&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d4684dcdc759dd9cdf41504698d737d8</td>\n      <td>2016-06-20 08:49:52 +0000</td>\n      <td>http://www.flipkart.com/santosh-royal-fashion-...</td>\n      <td>SANTOSH ROYAL FASHION Cotton Printed King size...</td>\n      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n      <td>BDSEJT9UQWHDUBH4</td>\n      <td>2699.0</td>\n      <td>1299.0</td>\n      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n      <td>False</td>\n      <td>...</td>\n      <td>santosh royal fashion king bedsheet royal bed...</td>\n      <td>santosh royal fashion king bedsheet royal beds...</td>\n      <td>santosh royal fashion king bedsheet royal beds...</td>\n      <td>santosh royal fashion king bedsheet royal beds...</td>\n      <td>384</td>\n      <td>Home Furnishing</td>\n      <td>Bed Linen</td>\n      <td>Bedsheets</td>\n      <td>SANTOSH ROYAL FASHION Bedsheets</td>\n      <td>&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6325b6870c54cd47be6ebfbffa620ec7</td>\n      <td>2016-06-20 08:49:52 +0000</td>\n      <td>http://www.flipkart.com/jaipur-print-cotton-fl...</td>\n      <td>Jaipur Print Cotton Floral King sized Double B...</td>\n      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n      <td>BDSEJTHNGWVGWWQU</td>\n      <td>2599.0</td>\n      <td>698.0</td>\n      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n      <td>False</td>\n      <td>...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet ...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet ...</td>\n      <td>king bedsheet king bedsheet bedsheet bedsheet ...</td>\n      <td>192</td>\n      <td>Home Furnishing</td>\n      <td>Bed Linen</td>\n      <td>Bedsheets</td>\n      <td>Jaipur Print Bedsheets</td>\n      <td>&gt;</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['first_category'] = df['product_category_tree'].str.extract(r'\\[\\\"(\\w* \\w*)')\n",
    "df['first_category'] = df['product_category_tree'].str.extract(r'^\\[\\\"(.+?)[\\>\\>]')\n",
    "df['second_category'] = df['product_category_tree'].str.extract(r'[\\>\\>](.+?)[\\>\\>]').replace(r'\\> ', '', regex=True)\n",
    "df['third_category'] = df['product_category_tree'].str.extract(r'[\\>\\>].+?[\\>\\>](.+?)[\\>\\>]').replace(r'\\> ', '', regex=True)\n",
    "df['fourth_category'] = df['product_category_tree'].str.extract(r'[\\>\\>].+?[\\>\\>].+?[\\>\\>](.+?)[\\>\\>]').replace(r'\\> ', '', regex=True)\n",
    "df['fifth_category'] = df['product_category_tree'].str.extract(r'[\\>\\>].+?[\\>\\>].+?[\\>\\>].+?[\\>\\>](.+?)').replace(r'\\> ', '', regex=True)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qVl9rUuDZau9",
    "outputId": "fe7318ee-5f1a-4f5d-e360-67135d0ce33b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                             uniq_id  crawl_timestamp  product_url  \\\nfirst_category                                                       \nBaby Care                        150              150          150   \nBeauty and Personal Care         150              150          150   \nComputers                        150              150          150   \nHome Decor & Festive Needs       150              150          150   \nHome Furnishing                  150              150          150   \nKitchen & Dining                 150              150          150   \nWatches                          150              150          150   \n\n                             product_name  product_category_tree  pid  \\\nfirst_category                                                          \nBaby Care                             150                    150  150   \nBeauty and Personal Care              150                    150  150   \nComputers                             150                    150  150   \nHome Decor & Festive Needs            150                    150  150   \nHome Furnishing                       150                    150  150   \nKitchen & Dining                      150                    150  150   \nWatches                               150                    150  150   \n\n                             retail_price  discounted_price  image  \\\nfirst_category                                                       \nBaby Care                             149               149    150   \nBeauty and Personal Care              150               150    150   \nComputers                             150               150    150   \nHome Decor & Festive Needs            150               150    150   \nHome Furnishing                       150               150    150   \nKitchen & Dining                      150               150    150   \nWatches                               150               150    150   \n\n                             is_FK_Advantage_product  ...  \\\nfirst_category                                        ...   \nBaby Care                                        150  ...   \nBeauty and Personal Care                         150  ...   \nComputers                                        150  ...   \nHome Decor & Festive Needs                       150  ...   \nHome Furnishing                                  150  ...   \nKitchen & Dining                                 150  ...   \nWatches                                          150  ...   \n\n                             product_specifications  descr_new  sentence_bow  \\\nfirst_category                                                                 \nBaby Care                                       150        150           150   \nBeauty and Personal Care                        150        150           150   \nComputers                                       150        150           150   \nHome Decor & Festive Needs                      149        150           150   \nHome Furnishing                                 150        150           150   \nKitchen & Dining                                150        150           150   \nWatches                                         150        150           150   \n\n                             sentence_bow_lem  sentence_dl  len_d  \\\nfirst_category                                                      \nBaby Care                                 150          150    150   \nBeauty and Personal Care                  150          150    150   \nComputers                                 150          150    150   \nHome Decor & Festive Needs                150          150    150   \nHome Furnishing                           150          150    150   \nKitchen & Dining                          150          150    150   \nWatches                                   150          150    150   \n\n                             second_category  third_category  fourth_category  \\\nfirst_category                                                                  \nBaby Care                                150             150              111   \nBeauty and Personal Care                 150             129              116   \nComputers                                150             148               40   \nHome Decor & Festive Needs               149             114               61   \nHome Furnishing                          148              42               10   \nKitchen & Dining                         150              86               66   \nWatches                                  150              10                1   \n\n                             fifth_category  \nfirst_category                               \nBaby Care                               111  \nBeauty and Personal Care                116  \nComputers                                40  \nHome Decor & Festive Needs               61  \nHome Furnishing                          10  \nKitchen & Dining                         66  \nWatches                                   1  \n\n[7 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniq_id</th>\n      <th>crawl_timestamp</th>\n      <th>product_url</th>\n      <th>product_name</th>\n      <th>product_category_tree</th>\n      <th>pid</th>\n      <th>retail_price</th>\n      <th>discounted_price</th>\n      <th>image</th>\n      <th>is_FK_Advantage_product</th>\n      <th>...</th>\n      <th>product_specifications</th>\n      <th>descr_new</th>\n      <th>sentence_bow</th>\n      <th>sentence_bow_lem</th>\n      <th>sentence_dl</th>\n      <th>len_d</th>\n      <th>second_category</th>\n      <th>third_category</th>\n      <th>fourth_category</th>\n      <th>fifth_category</th>\n    </tr>\n    <tr>\n      <th>first_category</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Baby Care</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>149</td>\n      <td>149</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>111</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>Beauty and Personal Care</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>129</td>\n      <td>116</td>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>Computers</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>148</td>\n      <td>40</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>Home Decor &amp; Festive Needs</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>149</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>149</td>\n      <td>114</td>\n      <td>61</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>Home Furnishing</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>148</td>\n      <td>42</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>Kitchen &amp; Dining</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>86</td>\n      <td>66</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>Watches</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>...</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catégories :  ['Baby Care ', 'Beauty and Personal Care ', 'Computers ', 'Home Decor & Festive Needs ', 'Home Furnishing ', 'Kitchen & Dining ', 'Watches ']\n",
      "[4, 0, 0, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 3, 5, 5, 4, 0, 4, 0, 1, 5, 5, 5, 2, 5, 1, 5, 2, 5, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 0, 1, 1, 4, 0, 3, 3, 0, 0, 3, 3, 5, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 4, 4, 4, 0, 4, 4, 4, 0, 3, 0, 5, 0, 2, 3, 0, 3, 2, 4, 0, 2, 3, 1, 1, 1, 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 5, 3, 5, 3, 3, 0, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 5, 3, 0, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 3, 5, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 3, 3, 5, 5, 0, 6, 6, 6, 6, 6, 4, 0, 6, 3, 6, 6, 4, 0, 3, 3, 0, 0, 0, 0, 5, 2, 0, 5, 3, 5, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 0, 2, 0, 2, 5, 2, 2, 2, 2, 2, 3, 1, 0, 4, 0, 1, 0, 4, 4, 2, 2, 2, 0, 0, 0, 4, 5, 4, 5, 5, 4, 4, 2, 1, 0, 5, 4, 1, 0, 0, 0, 0, 0, 5, 1, 5, 5, 1, 5, 1, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 2, 2, 2, 6, 6, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 0, 4, 0, 0, 3, 3, 3, 0, 2, 0, 3, 5, 6, 5, 2, 2, 1, 1, 1, 3, 3, 4, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 4, 0, 6, 4, 0, 0, 0, 0, 3, 4, 4, 3, 4, 4, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 4, 0, 4, 5, 0, 3, 5, 0, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 0, 3, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 3, 0, 3, 4, 3, 1, 4, 0, 2, 3, 1, 1, 1, 3, 5, 2, 6, 5, 5, 5, 5, 4, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 6, 6, 6, 6, 6, 6, 5, 5, 1, 1, 6, 0, 0, 0, 0, 0, 0, 0, 6, 1, 1, 6, 6, 6, 0, 0, 0, 6, 6, 6, 0, 6, 1, 1, 0, 1, 6, 6, 1, 1, 4, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 3, 3, 4, 4, 4, 1, 4, 3, 6, 4, 6, 6, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 0, 1, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 1, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 1, 3, 1, 3, 5, 3, 0, 3, 3, 0, 0, 0, 0, 3, 3, 6, 0, 0, 3, 3, 4, 3, 4, 3, 3, 3, 1, 3, 4, 4, 4, 3, 3, 4, 4, 3, 4, 1, 3, 3, 3, 4, 3, 4, 4, 3, 3, 4, 1, 3, 3, 4, 4, 3, 4, 4, 4, 3, 5, 3, 4, 4, 4, 4, 4, 4, 4, 1, 5, 0, 0, 4, 0, 0, 0, 3, 3, 0, 1, 0, 5, 0, 0, 0, 0, 0, 3, 1, 3, 3, 1, 3, 0, 5, 5, 4, 5, 0, 0, 3, 5, 4, 5, 0, 2, 5, 0, 1, 1, 1, 5, 3, 0, 0, 3, 1, 0, 2, 1, 4, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 1, 1, 2, 4, 2, 2, 2, 4, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Definizione l_cat e studio delle categorie\n",
    "cat_N1 = df.groupby(by='first_category').count().index.to_list()\n",
    "display(df.groupby(by='first_category').count())\n",
    "\n",
    "cat_N2 = df.groupby(by='second_category').count().index.to_list()\n",
    "# display(len(df.groupby(by='second_category').count().index.to_list()))\n",
    "\n",
    "l_cat = cat_N1\n",
    "\n",
    "print(\"catégories : \", l_cat)\n",
    "# y_cat_num = [(1-l_cat.index(df.iloc[i]['first_category'])) for i in range(len(df))]\n",
    "y_cat_num = [(l_cat.index(df.iloc[i]['first_category'])) for i in range(len(df))]\n",
    "print(y_cat_num)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Eov2YeJuZavA",
    "outputId": "40d40caf-b55c-452f-af57-a201375ae8a1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 Texte - Bag of Words\n",
    "Création des bags of words, réduction de dimensionalité, clustering pour un k fixé"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "RznvXP1nZavD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Créations des bags of words***"
   ],
   "metadata": {
    "id": "mkgH4VyCeLa8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "# création du bag of words (CountVectorizer et Tf-idf)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import manifold\n",
    "\n",
    "cvect = CountVectorizer(stop_words='english', max_df=0.95, min_df=1) # approche 1 - CV\n",
    "ctf = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=1) # approche 2 - td-idf\n",
    "\n",
    "feat = 'sentence_bow_lem'\n",
    "cv_fit = cvect.fit(df[feat]) # approche 1 - CV\n",
    "ctf_fit = ctf.fit(df[feat]) # approche 2 - td-idf\n",
    "\n",
    "cv_transform = cvect.transform(df[feat]) # approche 1 - CV\n",
    "ctf_transform = ctf.transform(df[feat]) # approche 2 - td-idf\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "H5bdw6F-ZavG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Réduction de dimensions (PCA et t-SNE) et clustering avec k fixé***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "DxG5y66wZavE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#Cellule résultats\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "#PCA reduction\n",
    "def pca_fct(df, graph=True):\n",
    "    pca = PCA(n_components=0.9, random_state=42, svd_solver ='full').fit(df) # svd_solver = 'full'\n",
    "    # If 0 < n_components < 1 and svd_solver == 'full', select the number of components\n",
    "    # such that the amount of variance that needs to be explained is greater\n",
    "    # than the percentage specified by n_components.\n",
    "    X = pca.transform(df)\n",
    "\n",
    "    return X\n",
    "\n",
    "# Modified for t-SNE calculation and visualisation\n",
    "def tSNE_e_kmeans(features, y_cat_num, num_clusters) :\n",
    "    time1 = time.time()\n",
    "    num_labels=len(l_cat)\n",
    "    tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000,\n",
    "                                 init='random', learning_rate=200, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(features)\n",
    "\n",
    "    # Détermination des clusters à partir des données après Tsne\n",
    "    cls = cluster.KMeans(n_clusters=num_clusters, n_init=100, random_state=42)\n",
    "    cls.fit(X_tsne)\n",
    "\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"tsne + clustering time : \", time2)\n",
    "\n",
    "    labels = cls.labels_\n",
    "\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "    scatter = ax.scatter(X_tsne[:,0],X_tsne[:,1], c=y_cat_num, cmap='Set1')\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=l_cat, loc=\"best\", title=\"Catégorie\")\n",
    "    plt.title('Représentation des produits par catégories réelles')\n",
    "\n",
    "    ax = fig.add_subplot(122)\n",
    "    scatter = ax.scatter(X_tsne[:,0],X_tsne[:,1], c=labels, cmap='Set1')\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=set(labels), loc=\"best\", title=\"Clusters\")\n",
    "    plt.title('Représentation des produits par clusters')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ARI = np.round(metrics.adjusted_rand_score(y_cat_num, labels),4)\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"n_clusters: %s\\n\" % num_clusters, \"ARI : \", ARI, \"time : %s \\n\\n-----------------------\" % time2)\n",
    "\n",
    "def bag_of_words(vect_for_pca, ind_vectorizer):\n",
    "    # ind_vectorizer - 0 for count vectoriser\n",
    "    # ind_vectorizer - 1 for Tfid\n",
    "    vectorizer = vectorizers[ind_vectorizer][0]\n",
    "    print('Vectorisation method: %s' % vectorizers[ind_vectorizer][1])\n",
    "    # fit et trasformation d'une colonne du dataframe, on obtient une sparse matrix\n",
    "    cvect_ft = vectorizer.fit_transform(vect_for_pca.astype('U')) \n",
    "    # PCA refuserait ce format, donc -> \n",
    "    \n",
    "    # print(cvect_ft)\n",
    "    # print(cvect_ft.dtype, cvect_ft.shape)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    df_for_pca = pd.DataFrame(cvect_ft.toarray(),columns=feature_names) \n",
    "    # -> d'une sparse matrix à dataframe accepté par PCA\n",
    "\n",
    "    X = pca_fct(df_for_pca) # Vectorisation du corpus\n",
    "\n",
    "    tSNE_e_kmeans(X, y_cat_num, num_labels)\n",
    "    # tSNE_e_kmeans(X, y_cat_num, 5) # le nombre de clusters peut être librement fixé ici\n",
    "\n",
    "scegli_vect_for_pca = [df['sentence_bow_lem']]\n",
    "nomi_scegli_vect_for_pca = ['df[\\'sentence_bow_lem\\']']\n",
    "num_labels=len(l_cat)\n",
    "n = 0\n",
    "for i_data in range(len(scegli_vect_for_pca)):\n",
    "    vect_for_pca = scegli_vect_for_pca[i_data]\n",
    "    print(i_data, nomi_scegli_vect_for_pca[i_data])\n",
    "\n",
    "    for j_ind_vectorizer in (0, 1):\n",
    "        n += 1\n",
    "        print(n)\n",
    "        cvect = CountVectorizer(encoding='utf-8', strip_accents='unicode', stop_words=stop_w, max_df=0.95, min_df=1) # approche 1 - CV\n",
    "        ctf = TfidfVectorizer(encoding='utf-8', strip_accents='unicode', stop_words=stop_w, max_df=0.95, min_df=1) # approche 2 - td-idf\n",
    "        vectorizers = [[cvect, 'CountVectorizer'], [ctf, 'TfidfVectorizer']]\n",
    "        vectorizer = vectorizers[j_ind_vectorizer][0]\n",
    "\n",
    "        vect_for_pca = scegli_vect_for_pca[i_data]\n",
    "        bag_of_words(vect_for_pca, j_ind_vectorizer)\n",
    "        print(\"Bag of words\")\n",
    "        print(\"Vectorizer: %s\" % vectorizers[j_ind_vectorizer][1])\n",
    "        print(\"Texte: %s\" % nomi_scegli_vect_for_pca[i_data])\n",
    "        print(\"n_clusters: %s\\n\\n-----------------------\\n\\n\" % nomi_scegli_vect_for_pca[i_data])\n",
    "\n",
    "#cvect_ft.get_feature_names_out()\n",
    "# print(X)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "G7wyL7JXZavN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 Approche k variable\n",
    "\n"
   ],
   "metadata": {
    "id": "LZ8buUdYbP9I",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les fonctions reflètent l'approche de balayer un interval de valeurs pour k.\n",
    "\n"
   ],
   "metadata": {
    "id": "apQczDvHgCl_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_name - CountVectorizer - 4 - 0.2309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zv/tmk76ddj1sj2bmhyt0by55l40000gp/T/ipykernel_3265/2671025204.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mnum_clusters\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m65\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m             \u001B[0mARI\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfor_table\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mind_feat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mind_vectorizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_clusters\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"%s - %s - %s - %s\"\u001B[0m  \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m \u001B[0mfeats\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mind_feat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvectorizers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mind_vectorizer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_clusters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mARI\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zv/tmk76ddj1sj2bmhyt0by55l40000gp/T/ipykernel_3265/2671025204.py\u001B[0m in \u001B[0;36mfor_table\u001B[0;34m(ind_feat, ind_vectorizer, num_clusters)\u001B[0m\n\u001B[1;32m     41\u001B[0m     tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000,\n\u001B[1;32m     42\u001B[0m                                  init='random', learning_rate=200, random_state=42)\n\u001B[0;32m---> 43\u001B[0;31m     \u001B[0mX_tsne\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtsne\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0;31m# Détermination des clusters à partir des données après Tsne\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m   1121\u001B[0m         \"\"\"\n\u001B[1;32m   1122\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_params_vs_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1123\u001B[0;31m         \u001B[0membedding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1124\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0membedding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1125\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001B[0m in \u001B[0;36m_fit\u001B[0;34m(self, X, skip_num_points)\u001B[0m\n\u001B[1;32m   1016\u001B[0m         \u001B[0mdegrees_of_freedom\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_components\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1017\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1018\u001B[0;31m         return self._tsne(\n\u001B[0m\u001B[1;32m   1019\u001B[0m             \u001B[0mP\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1020\u001B[0m             \u001B[0mdegrees_of_freedom\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001B[0m in \u001B[0;36m_tsne\u001B[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001B[0m\n\u001B[1;32m   1084\u001B[0m             \u001B[0mopt_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"momentum\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.8\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1085\u001B[0m             \u001B[0mopt_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"n_iter_without_progress\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_iter_without_progress\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1086\u001B[0;31m             \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkl_divergence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_gradient_descent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mopt_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1087\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1088\u001B[0m         \u001B[0;31m# Save the final number of iterations\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001B[0m in \u001B[0;36m_gradient_descent\u001B[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"compute_error\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_convergence\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mn_iter\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 398\u001B[0;31m         \u001B[0merror\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobjective\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    399\u001B[0m         \u001B[0mgrad_norm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    400\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001B[0m in \u001B[0;36m_kl_divergence_bh\u001B[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m     \u001B[0mgrad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_embedded\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     error = _barnes_hut_tsne.gradient(\n\u001B[0m\u001B[1;32m    280\u001B[0m         \u001B[0mval_P\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m         \u001B[0mX_embedded\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "# Cellule résultats et tableau\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# Écriture di stdout and stderr dans un fichier exterieur\n",
    "# sys.stdout = open('out.log', 'w')\n",
    "# sys.stderr = sys.stdout\n",
    "\n",
    "def for_table(ind_feat, ind_vectorizer, num_clusters):\n",
    "# ----------------- ok 7 ------ok 15 --------- ok 40 -----\n",
    "    feat_start = feats[ind_feat]\n",
    "    df['sentence_bow_lem'] = df[feat_start].apply(lambda x : transform_bow_lem_fct(x))\n",
    "\n",
    "    cvect = CountVectorizer(encoding='utf-8', strip_accents='unicode', stop_words=stop_w, max_df=0.95, min_df=1) # approche 1 - CV\n",
    "    ctf = TfidfVectorizer(encoding='utf-8', strip_accents='unicode', stop_words=stop_w, max_df=0.95, min_df=1) # approche 2 - td-idf\n",
    "    vectorizers = [[cvect, 'CountVectorizer'], [ctf, 'TfidfVectorizer']]\n",
    "    # ind_vectorizer - 0 for count vectoriser\n",
    "    # ind_vectorizer - 1 for Tfid\n",
    "    vectorizer = vectorizers[ind_vectorizer][0]\n",
    "\n",
    "    vect_for_pca = df['sentence_bow_lem']\n",
    "\n",
    "    # fit e trasforma una colonna del dataframe e ne ottiene una sparse matrix\n",
    "    cvect_ft = vectorizer.fit_transform(vect_for_pca.astype('U')) #Se questa la passi a PCA direttamente la rifiuta perché è una sparse matrix. Vedi errore 4\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    df_for_pca = pd.DataFrame(cvect_ft.toarray(),columns=feature_names) # da sparse matrix a dataframe accettato da PCA\n",
    "\n",
    "    pca = PCA(n_components=0.9, random_state=42, svd_solver ='full').fit(df_for_pca) # svd_solver = 'full'\n",
    "    # If 0 < n_components < 1 and svd_solver == 'full', select the number of components\n",
    "    # such that the amount of variance that needs to be explained is greater\n",
    "    # than the percentage specified by n_components.\n",
    "    X = pca.transform(df_for_pca)\n",
    "\n",
    "    # tSNE_e_kmeans\n",
    "    time1 = time.time()\n",
    "    num_labels=len(l_cat)\n",
    "    tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000,\n",
    "                                 init='random', learning_rate=200, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "    # Détermination des clusters à partir des données après Tsne\n",
    "    cls = cluster.KMeans(n_clusters=num_clusters, n_init=100, random_state=42)\n",
    "    cls.fit(X_tsne)\n",
    "\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "\n",
    "    labels = cls.labels_\n",
    "\n",
    "    ARI = np.round(metrics.adjusted_rand_score(y_cat_num, labels),4)\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "\n",
    "    return ARI\n",
    "\n",
    "\n",
    "filenamef = \"comparaison-bow.txt\"\n",
    "f = open(filenamef, 'w')\n",
    "\n",
    "num_labels=len(l_cat)\n",
    "n = 0\n",
    "feats = ['description', 'product_name', 'descr_new']\n",
    "vectorizers = [[cvect, 'CountVectorizer'], [ctf, 'TfidfVectorizer']]\n",
    "\n",
    "for ind_feat in range(1, len(feats)):\n",
    "    for ind_vectorizer in (0, 1):\n",
    "        for num_clusters in range(4, 65):\n",
    "\n",
    "            ARI = for_table(ind_feat, ind_vectorizer, num_clusters)\n",
    "\n",
    "            print(\"%s - %s - %s - %s\"  % ( feats[ind_feat], vectorizers[ind_vectorizer][1], num_clusters, ARI))\n",
    "            f.write(\"%s - %s - %s - %s\\n\"  % ( feats[ind_feat], vectorizers[ind_vectorizer][1], num_clusters, ARI))\n",
    "\n",
    "f.close"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4YWPxUY2ZavQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Graphique de comparaison de la performance selon le nombre de clusters\n",
    "\n"
   ],
   "metadata": {
    "id": "2ab7gqNzanxZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "x = np.arange(4, 65)\n",
    "x_df = pd.Series(x)\n",
    "\n",
    "lab = [\"CV - description\", \"td-idf - description\", \"CV - nom\", \"td-idf - nom\", \"CV - description + nom\", \"td-idf - description + nom\"]\n",
    "#for i in range(0, 6):\n",
    "for i in (0, 2, 4, 1, 3, 5):\n",
    "    # print(i)\n",
    "    #source_bow = 'traitement-bow/bow-tr-%s.txt' % i\n",
    "    source_bow = 'traitement-bow/bow-tr-%sb.txt' % int(i+1)\n",
    "    df = pd.read_csv(source_bow, sep= ' ', low_memory=False )\n",
    "    df.columns = ['clusters', 'ARI']\n",
    "    plt.xlim(4, 30)\n",
    "\n",
    "    plt.plot(df['clusters'], df['ARI'], label = lab[i])\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    #plt.plot(x_df, df)\n",
    "\n",
    "    #plt.plot(df['fruit'], df['quantity'])\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5PX7lf2AZavT"
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "colab": {
   "name": "MEREU_Ilaria-1-1-texte-bow.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}